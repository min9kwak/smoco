{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8867b0ed-5e66-4b8a-9e38-1f68bd3f24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 19 14:38:39 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0  On |                    0 |\n",
      "| N/A   42C    P0    94W / 300W |   8716MiB / 32505MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    98W / 300W |   6501MiB / 32508MiB |     80%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    36W / 300W |     15MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    60W / 300W |      9MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b963230-caf8-45bd-a724-6f7a2221076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bc59ea-cd6c-4ffd-a130-a461b1907bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import rich\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from configs.finetune import FinetuneConfig\n",
    "from tasks.classification import Classification\n",
    "\n",
    "from models.backbone.base import calculate_out_features\n",
    "from models.backbone.densenet import DenseNetBackbone\n",
    "from models.backbone.resnet import build_resnet_backbone\n",
    "from models.head.projector import MLPHead\n",
    "from models.head.classifier import LinearClassifier\n",
    "\n",
    "from datasets.brain import BrainProcessor, Brain, BrainMoCo\n",
    "from datasets.transforms import make_transforms, compute_statistics\n",
    "\n",
    "from utils.logging import get_rich_logger\n",
    "from utils.gpu import set_gpu\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4826b240-fe6f-4f19-b051-9a983495c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs =[(\"2022-07-02_08-00-31\", \"2022-07-03_13-41-32\"),\n",
    "        (\"2022-07-02_08-00-57\", \"2022-07-03_13-37-29\"),\n",
    "        (\"2022-07-02_09-38-52\", \"2022-07-03_13-33-23\"),\n",
    "        (\"2022-07-02_09-40-42\", \"2022-07-03_13-29-10\"),\n",
    "        (\"2022-07-02_11-17-38\", \"2022-07-03_13-25-05\"),\n",
    "        (\"2022-07-02_11-20-21\", \"2022-07-03_13-21-00\"),\n",
    "        (\"2022-07-02_17-15-14\", \"2022-07-03_13-16-54\"),\n",
    "        (\"2022-07-02_17-15-34\", \"2022-07-03_13-12-44\"),\n",
    "        (\"2022-07-02_18-53-46\", \"2022-07-03_13-08-35\"),\n",
    "        (\"2022-07-02_18-54-27\", \"2022-07-03_13-04-32\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff901a8-57f2-4e42-afc3-2583c4d94b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = ['3']\n",
    "server = 'dgx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584355c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import (\n",
    "    GradCAMpp,\n",
    "    OcclusionSensitivity,\n",
    "    SmoothGrad,\n",
    "    GuidedBackpropGrad,\n",
    "    GuidedBackpropSmoothGrad,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa95bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelViz(nn.Module):\n",
    "    def __init__(self, backbone, classifier, local_rank):\n",
    "        super(ModelViz, self).__init__()\n",
    "        self.local_rank = local_rank\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "        self._build_model(self.backbone, self.classifier)\n",
    "    \n",
    "    def _build_model(self, backbone, classifier):\n",
    "    \n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        self.backbone.to(self.local_rank)\n",
    "        self.classifier.to(self.local_rank)\n",
    "        \n",
    "        self.backbone.eval()\n",
    "        self.classifier.eval()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.classifier(self.backbone(x))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 565/565 [45:16<00:00,  4.81s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 56/56 [03:58<00:00,  4.25s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 565/565 [45:42<00:00,  4.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 56/56 [04:19<00:00,  4.63s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 551/551 [43:51<00:00,  4.78s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 70/70 [05:20<00:00,  4.58s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 551/551 [44:15<00:00,  4.82s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 70/70 [04:44<00:00,  4.07s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 567/567 [44:59<00:00,  4.76s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 54/54 [03:46<00:00,  4.19s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 567/567 [45:49<00:00,  4.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 54/54 [03:36<00:00,  4.00s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 565/565 [44:42<00:00,  4.75s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 56/56 [04:09<00:00,  4.45s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 565/565 [46:30<00:00,  4.94s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 56/56 [04:05<00:00,  4.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 553/553 [46:00<00:00,  4.99s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 68/68 [04:08<00:00,  3.65s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 553/553 [44:02<00:00,  4.78s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 68/68 [04:07<00:00,  3.64s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 553/553 [45:58<00:00,  4.99s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 68/68 [05:01<00:00,  4.44s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 553/553 [43:32<00:00,  4.72s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 68/68 [05:04<00:00,  4.48s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 548/548 [41:32<00:00,  4.55s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 73/73 [04:59<00:00,  4.10s/it]\n",
      " 11%|█████████▏                                                                        | 61/548 [04:28<34:22,  4.24s/it]"
     ]
    }
   ],
   "source": [
    "for hash in hashs:\n",
    "    for layer in['layer1', 'layer2']:\n",
    "\n",
    "        # Individual Heatmap    \n",
    "        config = edict()\n",
    "        config.server = server\n",
    "        config.gpus = gpus\n",
    "        local_rank = 0\n",
    "\n",
    "        config.finetune_file = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/ckpt.last.pth.tar')\n",
    "        finetune_config = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/configs.json')\n",
    "        with open(finetune_config, 'rb') as fb:\n",
    "            finetune_config = json.load(fb)\n",
    "\n",
    "        finetune_config_names = [\n",
    "            # data_parser\n",
    "            'data_type', 'root', 'data_info', 'mci_only', 'n_splits', 'n_cv',\n",
    "            'image_size', 'small_kernel', 'random_state',\n",
    "            'intensity', 'crop', 'crop_size', 'rotate', 'flip', 'affine', 'blur', 'blur_std', 'prob',\n",
    "            # model_parser\n",
    "            'backbone_type', 'init_features', 'growth_rate', 'block_config', 'bn_size', 'dropout_rate',\n",
    "            'arch', 'no_max_pool',\n",
    "            # train\n",
    "            'batch_size',\n",
    "            # moco / supmoco\n",
    "            'alphas',\n",
    "            # others\n",
    "            'task', 'projector_dim'\n",
    "        ]\n",
    "\n",
    "        for name in finetune_config_names:\n",
    "            if name in finetune_config.keys():\n",
    "                setattr(config, name, finetune_config[name])\n",
    "\n",
    "        #########################################\n",
    "        set_gpu(config)\n",
    "        np.random.seed(config.random_state)\n",
    "        torch.manual_seed(config.random_state)\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        torch.cuda.set_device(local_rank)\n",
    "\n",
    "        # Networks\n",
    "        if config.backbone_type == 'densenet':\n",
    "            backbone = DenseNetBackbone(in_channels=1,\n",
    "                                        init_features=config.init_features,\n",
    "                                        growth_rate=config.growth_rate,\n",
    "                                        block_config=config.block_config,\n",
    "                                        bn_size=config.bn_size,\n",
    "                                        dropout_rate=config.dropout_rate,\n",
    "                                        semi=False)\n",
    "            activation = True\n",
    "        elif config.backbone_type == 'resnet':\n",
    "            backbone = build_resnet_backbone(arch=config.arch,\n",
    "                                             no_max_pool=config.no_max_pool,\n",
    "                                             in_channels=1,\n",
    "                                             semi=False)\n",
    "            activation = False\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if config.small_kernel:\n",
    "            backbone._fix_first_conv()\n",
    "\n",
    "        if config.crop:\n",
    "            out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.crop_size)\n",
    "        else:\n",
    "            out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.image_size)\n",
    "        classifier = LinearClassifier(in_channels=out_dim, num_classes=2, activation=activation)\n",
    "\n",
    "        backbone.load_weights_from_checkpoint(path=config.finetune_file, key='backbone')\n",
    "        classifier.load_weights_from_checkpoint(path=config.finetune_file, key='classifier')\n",
    "\n",
    "        # load finetune data\n",
    "        data_processor = BrainProcessor(root=config.root,\n",
    "                                        data_info=config.data_info,\n",
    "                                        data_type=config.data_type,\n",
    "                                        mci_only=config.mci_only,\n",
    "                                        random_state=config.random_state)\n",
    "        datasets = data_processor.process(n_splits=config.n_splits, n_cv=config.n_cv)\n",
    "\n",
    "        # intensity normalization\n",
    "        assert config.intensity in [None, 'scale', 'minmax']\n",
    "        mean_std, min_max = (None, None), (None, None)\n",
    "        if config.intensity is None:\n",
    "            pass\n",
    "        elif config.intensity == 'scale':\n",
    "            pass\n",
    "        elif config.intensity == 'minmax':\n",
    "            with open(os.path.join(config.root, 'labels/minmax.pkl'), 'rb') as fb:\n",
    "                minmax_stats = pickle.load(fb)\n",
    "                min_max = (minmax_stats[config.data_type]['min'], minmax_stats[config.data_type]['max'])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        train_transform, test_transform = make_transforms(image_size=config.image_size,\n",
    "                                                          intensity=config.intensity,\n",
    "                                                          min_max=min_max,\n",
    "                                                          crop_size=config.crop_size,\n",
    "                                                          rotate=config.rotate,\n",
    "                                                          flip=config.flip,\n",
    "                                                          affine=config.affine,\n",
    "                                                          blur_std=config.blur_std,\n",
    "                                                          prob=config.prob)\n",
    "\n",
    "        #########################################\n",
    "        train_set = Brain(dataset=datasets['train'], data_type=config.data_type, transform=test_transform)\n",
    "        test_set = Brain(dataset=datasets['test'], data_type=config.data_type, transform=test_transform)\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_set, batch_size=1, drop_last=False)\n",
    "        test_loader = DataLoader(dataset=test_set, batch_size=1, drop_last=False)\n",
    "\n",
    "\n",
    "        ###############\n",
    "        model = ModelViz(backbone=backbone, classifier=classifier, local_rank=local_rank)\n",
    "        gcam = GradCAMpp(model, f'backbone.{layer}')\n",
    "\n",
    "        import torch.optim as optim\n",
    "        optimizer = optim.AdamW(model.parameters())\n",
    "        \n",
    "        ##############\n",
    "        # save individual\n",
    "        for mode, dset, loader in zip(['train', 'test'], [train_set, test_set], [train_loader, test_loader]):\n",
    "\n",
    "            path = f'gcam/{layer}/{hash[0]}-{hash[1]}/{mode}'\n",
    "            os.makedirs(path + '-converter', exist_ok=True)\n",
    "            os.makedirs(path + '-nonconverter', exist_ok=True)\n",
    "\n",
    "            for batch in tqdm.tqdm(loader):\n",
    "\n",
    "                x = batch['x'].to(local_rank)\n",
    "                idx = batch['idx'].item()\n",
    "                                \n",
    "                logit = model(x)\n",
    "                logit = logit.detach()\n",
    "                confidence = \"{:.3f}\".format(logit.softmax(dim=1)[0, batch['y'].item()].item())\n",
    "                \n",
    "                # correctly classified\n",
    "                if batch['y'].item() == logit.argmax().item():\n",
    "                    \n",
    "                    for reverse in [True, False]:\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        gcam_map = gcam(x)\n",
    "                        gcam_map = gcam_map.cpu().numpy()[0][0]\n",
    "                        if reverse:\n",
    "                            gcam_map = np.abs(1 - gcam_map)\n",
    "                            \n",
    "                        if not np.isnan(gcam_map).any():\n",
    "                            # status\n",
    "                            if batch['y'].item() == 0:\n",
    "                                status = 'nonconverter'\n",
    "                            else:\n",
    "                                status = 'converter'\n",
    "                            # heatmap\n",
    "                            pet_file = dset.pet[idx]                        \n",
    "                            pet_id = pet_file.split('/')[-1].replace('.pkl', '')\n",
    "                            with open(pet_file, 'rb') as fb:\n",
    "                                pet = pickle.load(fb)\n",
    "\n",
    "                            mask = pet <= 0\n",
    "\n",
    "                            gcam_map = resize(gcam_map, [145, 145, 145])\n",
    "                            gcam_map[mask] = np.nan\n",
    "                            \n",
    "                            fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "                            axs[0, 0].imshow(pet[72, :, :], cmap='binary')\n",
    "                            axs[0, 1].imshow(gcam_map[72, :, :], cmap='jet')\n",
    "\n",
    "                            axs[1, 0].imshow(pet[:, 72, :], cmap='binary')\n",
    "                            axs[1, 1].imshow(gcam_map[:, 72, :], cmap='jet')\n",
    "\n",
    "                            axs[2, 0].imshow(pet[:, :, 90], cmap='binary')\n",
    "                            axs[2, 1].imshow(gcam_map[:, :, 90], cmap='jet')\n",
    "                            plt.savefig(\n",
    "                                path + '-' + status + f'/{pet_id}-{confidence}-{reverse}.png',\n",
    "                                dpi=300,\n",
    "                                bbox_inches='tight'\n",
    "                            )\n",
    "                            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040261c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save average-train\n",
    "converter = []\n",
    "nonconverter = []\n",
    "\n",
    "for batch in tqdm.tqdm(train_loader):\n",
    "\n",
    "    x = batch['x'].to(local_rank)\n",
    "    logit = model(x)    \n",
    "    idx = batch['idx'].item()\n",
    "\n",
    "    # correctly classified\n",
    "    if batch['y'].item() == logit.argmax().item():\n",
    "        gcam_map = gcam(x)\n",
    "        gcam_map = gcam_map.cpu().numpy()[0][0]\n",
    "        # gcam_map = np.abs(1 - gcam_map)\n",
    "        # gcam_map = np.log(1 + gcam_map)\n",
    "\n",
    "        if not np.isnan(gcam_map).any():\n",
    "\n",
    "            pet_file = train_set.pet[idx]\n",
    "            pet_id = pet_file.split('/')[-1].replace('.pkl', '')\n",
    "            with open(pet_file, 'rb') as fb:\n",
    "                pet = pickle.load(fb)\n",
    "\n",
    "            mask = pet <= 0\n",
    "\n",
    "            gcam_map = resize(gcam_map, [145, 145, 145])\n",
    "            # gcam_map[mask] = np.nan\n",
    "            \n",
    "            # status\n",
    "            if batch['y'].item() == 0:\n",
    "                nonconverter.append(gcam_map)\n",
    "                nonconverter_pet = pet\n",
    "                nonconverter_mask = mask\n",
    "            else:\n",
    "                converter.append(gcam_map)\n",
    "                converter_pet = pet\n",
    "                converter_mask = mask\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4fd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(converter)\n",
    "a = np.mean(a, axis=0)\n",
    "a[converter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(converter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(a[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(converter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(a[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(converter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(a[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90653fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(nonconverter)\n",
    "a = np.mean(a, axis=0)\n",
    "a[nonconverter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(nonconverter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(a[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(nonconverter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(a[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(nonconverter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(a[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(converter)\n",
    "b = np.array(nonconverter)\n",
    "c = np.concatenate([a, b], axis=0)\n",
    "\n",
    "c = np.mean(c, axis=0)\n",
    "c[nonconverter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(nonconverter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(c[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(nonconverter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(c[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(nonconverter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(c[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save average-test\n",
    "converter = []\n",
    "nonconverter = []\n",
    "\n",
    "for batch in tqdm.tqdm(test_loader):\n",
    "\n",
    "    x = batch['x'].to(local_rank)\n",
    "    logit = model(x)    \n",
    "    idx = batch['idx'].item()\n",
    "\n",
    "    # correctly classified\n",
    "    if batch['y'].item() == logit.argmax().item():\n",
    "        gcam_map = gcam(x)\n",
    "        gcam_map = gcam_map.cpu().numpy()[0][0]\n",
    "        # gcam_map = np.abs(1 - gcam_map)\n",
    "        # gcam_map = np.log(1 + gcam_map)\n",
    "\n",
    "        if not np.isnan(gcam_map).any():\n",
    "\n",
    "            pet_file = test_set.pet[idx]\n",
    "            pet_id = pet_file.split('/')[-1].replace('.pkl', '')\n",
    "            with open(pet_file, 'rb') as fb:\n",
    "                pet = pickle.load(fb)\n",
    "\n",
    "            mask = pet <= 0\n",
    "\n",
    "            gcam_map = resize(gcam_map, [145, 145, 145])\n",
    "            # gcam_map[mask] = np.nan\n",
    "            \n",
    "            # status\n",
    "            if batch['y'].item() == 0:\n",
    "                nonconverter.append(gcam_map)\n",
    "                nonconverter_pet = pet\n",
    "                nonconverter_mask = mask\n",
    "            else:\n",
    "                converter.append(gcam_map)\n",
    "                converter_pet = pet\n",
    "                converter_mask = mask\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(converter)\n",
    "a = np.mean(a, axis=0)\n",
    "a[converter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(converter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(a[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(converter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(a[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(converter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(a[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(nonconverter)\n",
    "a = np.mean(a, axis=0)\n",
    "a[nonconverter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(nonconverter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(a[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(nonconverter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(a[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(nonconverter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(a[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77f717-3335-4ee8-8557-9efec6b4dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(converter)\n",
    "b = np.array(nonconverter)\n",
    "c = np.concatenate([a, b], axis=0)\n",
    "\n",
    "c = np.mean(c, axis=0)\n",
    "c[nonconverter_mask] = np.nan\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "axs[0, 0].imshow(nonconverter_pet[72, :, :], cmap='binary')\n",
    "axs[0, 1].imshow(c[72, :, :], cmap='jet')\n",
    "\n",
    "axs[1, 0].imshow(nonconverter_pet[:, 72, :], cmap='binary')\n",
    "axs[1, 1].imshow(c[:, 72, :], cmap='jet')\n",
    "\n",
    "axs[2, 0].imshow(nonconverter_pet[:, :, 90], cmap='binary')\n",
    "axs[2, 1].imshow(c[:, :, 90], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5bd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
