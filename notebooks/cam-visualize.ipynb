{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8867b0ed-5e66-4b8a-9e38-1f68bd3f24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 27 18:21:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   58C    P0   152W / 300W |  21027MiB / 32505MiB |     88%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   177W / 300W |  23994MiB / 32508MiB |     87%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    55W / 300W |  11814MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    68W / 300W |     13MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b963230-caf8-45bd-a724-6f7a2221076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bc59ea-cd6c-4ffd-a130-a461b1907bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import rich\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from configs.finetune import FinetuneConfig\n",
    "from tasks.classification import Classification\n",
    "\n",
    "from models.backbone.base import calculate_out_features\n",
    "from models.backbone.densenet import DenseNetBackbone\n",
    "from models.backbone.resnet import build_resnet_backbone\n",
    "from models.head.projector import MLPHead\n",
    "from models.head.classifier import LinearClassifier\n",
    "\n",
    "from datasets.brain import BrainProcessor, Brain, BrainMoCo\n",
    "from datasets.transforms import make_transforms, compute_statistics\n",
    "\n",
    "from utils.logging import get_rich_logger\n",
    "from utils.gpu import set_gpu\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4826b240-fe6f-4f19-b051-9a983495c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs =[(\"2022-07-02_08-00-31\", \"2022-07-03_13-41-32\"),\n",
    "        (\"2022-07-02_08-00-57\", \"2022-07-03_13-37-29\"),\n",
    "        (\"2022-07-02_09-38-52\", \"2022-07-03_13-33-23\"),\n",
    "        (\"2022-07-02_09-40-42\", \"2022-07-03_13-29-10\"),\n",
    "        (\"2022-07-02_11-17-38\", \"2022-07-03_13-25-05\"),\n",
    "        (\"2022-07-02_11-20-21\", \"2022-07-03_13-21-00\"),\n",
    "        (\"2022-07-02_17-15-14\", \"2022-07-03_13-16-54\"),\n",
    "        (\"2022-07-02_17-15-34\", \"2022-07-03_13-12-44\"),\n",
    "        (\"2022-07-02_18-53-46\", \"2022-07-03_13-08-35\"),\n",
    "        (\"2022-07-02_18-54-27\", \"2022-07-03_13-04-32\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff901a8-57f2-4e42-afc3-2583c4d94b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = ['3']\n",
    "server = 'dgx'\n",
    "hash = hashs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000b5b46-025c-4a96-86f4-8bbb209761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict()\n",
    "config.server = server\n",
    "config.gpus = gpus\n",
    "local_rank = 0\n",
    "\n",
    "config.finetune_file = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/ckpt.last.pth.tar')\n",
    "finetune_config = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/configs.json')\n",
    "with open(finetune_config, 'rb') as fb:\n",
    "    finetune_config = json.load(fb)\n",
    "\n",
    "finetune_config_names = [\n",
    "    # data_parser\n",
    "    'data_type', 'root', 'data_info', 'mci_only', 'n_splits', 'n_cv',\n",
    "    'image_size', 'small_kernel', 'random_state',\n",
    "    'intensity', 'crop', 'crop_size', 'rotate', 'flip', 'affine', 'blur', 'blur_std', 'prob',\n",
    "    # model_parser\n",
    "    'backbone_type', 'init_features', 'growth_rate', 'block_config', 'bn_size', 'dropout_rate',\n",
    "    'arch', 'no_max_pool',\n",
    "    # train\n",
    "    'batch_size',\n",
    "    # moco / supmoco\n",
    "    'alphas',\n",
    "    # others\n",
    "    'task', 'projector_dim'\n",
    "]\n",
    "\n",
    "for name in finetune_config_names:\n",
    "    if name in finetune_config.keys():\n",
    "        setattr(config, name, finetune_config[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9e4422-5734-4179-9adb-bc3c79969a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu(config)\n",
    "np.random.seed(config.random_state)\n",
    "torch.manual_seed(config.random_state)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.cuda.set_device(local_rank)\n",
    "\n",
    "# Networks\n",
    "if config.backbone_type == 'densenet':\n",
    "    backbone = DenseNetBackbone(in_channels=1,\n",
    "                                init_features=config.init_features,\n",
    "                                growth_rate=config.growth_rate,\n",
    "                                block_config=config.block_config,\n",
    "                                bn_size=config.bn_size,\n",
    "                                dropout_rate=config.dropout_rate,\n",
    "                                semi=False)\n",
    "    activation = True\n",
    "elif config.backbone_type == 'resnet':\n",
    "    backbone = build_resnet_backbone(arch=config.arch,\n",
    "                                     no_max_pool=config.no_max_pool,\n",
    "                                     in_channels=1,\n",
    "                                     semi=False)\n",
    "    activation = False\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if config.small_kernel:\n",
    "    backbone._fix_first_conv()\n",
    "\n",
    "if config.crop:\n",
    "    out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.crop_size)\n",
    "else:\n",
    "    out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.image_size)\n",
    "classifier = LinearClassifier(in_channels=out_dim, num_classes=2, activation=activation)\n",
    "\n",
    "backbone.load_weights_from_checkpoint(path=config.finetune_file, key='backbone')\n",
    "classifier.load_weights_from_checkpoint(path=config.finetune_file, key='classifier')\n",
    "\n",
    "# load finetune data\n",
    "data_processor = BrainProcessor(root=config.root,\n",
    "                                data_info=config.data_info,\n",
    "                                data_type=config.data_type,\n",
    "                                mci_only=config.mci_only,\n",
    "                                random_state=config.random_state)\n",
    "datasets = data_processor.process(n_splits=config.n_splits, n_cv=config.n_cv)\n",
    "\n",
    "# intensity normalization\n",
    "assert config.intensity in [None, 'scale', 'minmax']\n",
    "mean_std, min_max = (None, None), (None, None)\n",
    "if config.intensity is None:\n",
    "    pass\n",
    "elif config.intensity == 'scale':\n",
    "    pass\n",
    "elif config.intensity == 'minmax':\n",
    "    with open(os.path.join(config.root, 'labels/minmax.pkl'), 'rb') as fb:\n",
    "        minmax_stats = pickle.load(fb)\n",
    "        min_max = (minmax_stats[config.data_type]['min'], minmax_stats[config.data_type]['max'])\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_transform, test_transform = make_transforms(image_size=config.image_size,\n",
    "                                                  intensity=config.intensity,\n",
    "                                                  mean_std=mean_std,\n",
    "                                                  min_max=min_max,\n",
    "                                                  crop=config.crop,\n",
    "                                                  crop_size=config.crop_size,\n",
    "                                                  rotate=config.rotate,\n",
    "                                                  flip=config.flip,\n",
    "                                                  affine=config.affine,\n",
    "                                                  blur=config.blur,\n",
    "                                                  blur_std=config.blur_std,\n",
    "                                                  prob=config.prob)\n",
    "\n",
    "train_set = Brain(dataset=datasets['train'], data_type=config.data_type, transform=test_transform)\n",
    "test_set = Brain(dataset=datasets['test'], data_type=config.data_type, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=16, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014b6e13-2664-453c-9647-2f70626d50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import (\n",
    "    GradCAMpp,\n",
    "    OcclusionSensitivity,\n",
    "    SmoothGrad,\n",
    "    GuidedBackpropGrad,\n",
    "    GuidedBackpropSmoothGrad,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a6aa29-e364-44e0-ac47-ad5e5d3d962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelViz(nn.Module):\n",
    "    def __init__(self, local_rank):\n",
    "        super(ModelViz, self).__init__()\n",
    "        self.local_rank = local_rank\n",
    "    \n",
    "    def _build_model(self, backbone, classifier):\n",
    "    \n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        self.backbone.to(self.local_rank)\n",
    "        self.classifier.to(self.local_rank)\n",
    "        \n",
    "        self.backbone.eval()\n",
    "        self.classifier.eval()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.classifier(self.backbone(x))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9a150f-0429-4766-95ca-f24223fa3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelViz(local_rank)\n",
    "model._build_model(backbone, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8eb078-7b02-42be-be53-0b80272a2dc7",
   "metadata": {},
   "source": [
    "## Check evaluation performance and prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7d553e-ddc8-4e20-a890-635fa78476c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6e0181-3519-4222-9c8b-65e7ca775289",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, local_rank=0, adjusted=False):\n",
    "    \"\"\"Evaluation defined for a single epoch.\"\"\"\n",
    "\n",
    "    steps = len(data_loader)\n",
    "    model.backbone.eval()\n",
    "    model.classifier.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        x = batch['x'].float().to(local_rank)\n",
    "        y = batch['y'].to(local_rank)\n",
    "        logits = model(x)        \n",
    "        y_true.append(y.long())\n",
    "        y_pred.append(logits)\n",
    "\n",
    "    # accuracy and macro f1 score\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0).to(torch.float32)\n",
    "\n",
    "    clf_result = classification_result(y_true=y_true.cpu().numpy(),\n",
    "                                       y_pred=y_pred.softmax(1).detach().cpu().numpy(),\n",
    "                                       adjusted=adjusted)\n",
    "    result = {}\n",
    "    for k, v in clf_result.items():\n",
    "        result[k] = v\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ff3181-bdae-4c63-82fb-903f95e6b7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.875, 'auroc': 0.9382113821138212, 'sens': 0.7999999946666667, 'spec': 0.902439022189173, 'prec': 0.7499999953125, 'f1': 0.774193493444332, 'gmean': 0.84967712275801}\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate(model=model, data_loader=test_loader, local_rank=0, adjusted=True)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d83e138-c07a-4201-a240-f7af5e87e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_prediction(model, data_loader, local_rank=0, adjusted=False):\n",
    "    \"\"\"Evaluation defined for a single epoch.\"\"\"\n",
    "\n",
    "    steps = len(data_loader)\n",
    "    model.backbone.eval()\n",
    "    model.classifier.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    idx = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        x = batch['x'].float().to(local_rank)\n",
    "        y = batch['y'].to(local_rank)\n",
    "        \n",
    "        logits = model(x)        \n",
    "        y_true.append(y.long())\n",
    "        y_pred.append(logits)\n",
    "        idx.append(batch['idx'])\n",
    "\n",
    "    # accuracy and macro f1 score\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0).to(torch.float32)\n",
    "    idx = torch.cat(idx, dim=0)\n",
    "    return y_true, y_pred, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ba468b-e0db-4bad-b638-2a60749ea29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, idx = sample_prediction(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5c62eb-9672-475e-b53f-99c1933118e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmci_idx, smci_idx = [], []\n",
    "for t, p, i in zip(y_true, y_pred.softmax(1), idx):\n",
    "    if torch.argmax(p) == t:\n",
    "        if t == 0:\n",
    "            if p[t].item() > 0.95:\n",
    "                smci_idx.append(i.item())\n",
    "        if t == 1:\n",
    "            if p[t].item() > 0.95:\n",
    "                pmci_idx.append(i.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb5c729-76d1-42b8-91ea-543b2d7b6198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1 (99.92%) | True: 1\n",
      "Pred: 1 (99.92%) | True: 1\n",
      "Pred: 1 (99.93%) | True: 1\n",
      "Pred: 1 (97.26%) | True: 1\n",
      "Pred: 1 (99.74%) | True: 1\n",
      "Pred: 1 (99.82%) | True: 1\n",
      "Pred: 1 (99.42%) | True: 1\n",
      "Pred: 1 (99.57%) | True: 1\n"
     ]
    }
   ],
   "source": [
    "pmci_set = np.array(Subset(test_set, pmci_idx))\n",
    "for d in pmci_set:\n",
    "    logits = model(d['x'][None].to(local_rank))\n",
    "    model.zero_grad()\n",
    "    pred_label = logits.argmax(dim=1).item()\n",
    "    pred_prob = torch.nn.functional.softmax(logits, dim=1)[0, pred_label].item() * 100\n",
    "    print(f\"Pred: {pred_label} ({pred_prob:.2f}%) | True: {d['y']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80055445-0bed-4e91-8bcd-f00a24dfca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyparam = edict()\n",
    "hyparam.vmin = 0.3\n",
    "hyparam.loc1 = 80\n",
    "hyparam.loc2 = 60\n",
    "hyparam.loc3 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b74877-82e5-4ed9-b554-28052d76c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slice(pkl, hyparam):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 12))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].imshow(pkl[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[1].imshow(pkl[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[2].imshow(pkl[:, :, hyparam.loc3], cmap='binary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200d71da-e436-4d3f-918d-49f1fbbcdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(data, target_layer, model, local_rank):\n",
    "    \n",
    "    model.backbone.eval()\n",
    "    model.classifier.eval()\n",
    "    \n",
    "    gcam = GradCAMpp(model, target_layer)\n",
    "    guided = GuidedBackpropGrad(model)\n",
    "    \n",
    "    # predict\n",
    "    x = torch.as_tensor(data['x'][None].to(local_rank))        \n",
    "    pred_logits = model(x)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    pred_label = pred_logits.argmax(dim=1).item()\n",
    "    pred_prob = torch.nn.functional.softmax(pred_logits, dim=1)[0, pred_label].item() * 100\n",
    "\n",
    "    title = f\"Pred: {pred_label} ({pred_prob:.2f}%) | True: {data['y']}\"\n",
    "\n",
    "    # image\n",
    "    img = torch.moveaxis(x, 1, -1)\n",
    "\n",
    "    # gradcam\n",
    "    gcam_map = gcam(x=x, class_idx=pred_label)[0]\n",
    "    model.zero_grad()\n",
    "\n",
    "    # guided\n",
    "    guided_map = guided(x)\n",
    "    model.zero_grad()\n",
    "    guided_map = torch.sum(guided_map ** 2, dim=1) ** 0.5\n",
    "    \n",
    "    # shape\n",
    "    img = img.cpu().detach().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    \n",
    "    gcam_map = gcam_map.cpu().detach().numpy()\n",
    "    gcam_map = np.squeeze(gcam_map)\n",
    "    \n",
    "    guided_map = guided_map.cpu().detach().numpy()\n",
    "    guided_map = np.squeeze(guided_map)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    return img, gcam_map, guided_map, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ec12caa-b50d-429f-8a54-19200c275e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../cam/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43e410ef-9f3d-49f9-a29d-bf1ae2e8f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n"
     ]
    }
   ],
   "source": [
    "for layer in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    print(layer)\n",
    "    os.makedirs(f'../cam/{layer}', exist_ok=True)\n",
    "    for i in pmci_idx:\n",
    "\n",
    "        # load data\n",
    "        stripped_pet_file = test_set.pet[i]\n",
    "        stripped_mri_file = test_set.mri[i]\n",
    "\n",
    "        pet_id = stripped_pet_file.split('/')[-1].replace('.pkl', '')\n",
    "        mri_id = stripped_mri_file.split('/')[-1].replace('.pkl', '')\n",
    "\n",
    "        with open(stripped_mri_file, 'rb') as fb:\n",
    "            stripped_mri = pickle.load(fb)\n",
    "\n",
    "        with open(stripped_pet_file, 'rb') as fb:\n",
    "            stripped_pet = pickle.load(fb)\n",
    "\n",
    "        nonstripped_pet_file = '/raidWorkspace/mingu/Data/ADNI/PUP_FBP/{}/pet_proc/w_{}_SUVR.nii.gz'.format(pet_id, pet_id)\n",
    "        nonstripped_pet = nib.load(nonstripped_pet_file).get_fdata()\n",
    "        nonstripped_pet = np.pad(nonstripped_pet, ((12, 12), (0, 0), (12, 12)), 'constant')\n",
    "\n",
    "        # get activation map\n",
    "        temp_set = np.array(Subset(test_set, [i]))\n",
    "        d = temp_set[0]\n",
    "        img, gcamp_map, guided_map, title = get_map(d, f'backbone.{layer}', model, local_rank)\n",
    "\n",
    "        gcamp_map_t = np.abs(1 - gcamp_map)\n",
    "        tr = resize(gcamp_map_t, [145, 145, 145])\n",
    "        tr_m = tr.copy()\n",
    "        bmask = stripped_pet <= 0\n",
    "        tr_m[bmask] = np.nan\n",
    "\n",
    "        m = tr_m < hyparam.vmin\n",
    "        tr_m[m] = np.nan\n",
    "\n",
    "        # show map\n",
    "        fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "        plt.suptitle(title + f' | {mri_id} | {pet_id}')\n",
    "\n",
    "        axs[0, 0].imshow(stripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 1].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "        axs[0, 2].imshow(nonstripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 2].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "        axs[0, 3].imshow(stripped_mri[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 3].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        axs[1, 0].imshow(stripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 1].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "        axs[1, 2].imshow(nonstripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 2].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "        axs[1, 3].imshow(stripped_mri[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 3].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        axs[2, 0].imshow(stripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 1].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "        axs[2, 2].imshow(nonstripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 2].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "        axs[2, 3].imshow(stripped_mri[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 3].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        plt.savefig(f'../cam/{layer}/{mri_id}_{pet_id}.png', dpi=400,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9806ebce-3651-49de-901e-b1040cbe81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(f'../guided/', exist_ok=True)\n",
    "for i in pmci_idx:\n",
    "\n",
    "    # load data\n",
    "    stripped_pet_file = test_set.pet[i]\n",
    "    stripped_mri_file = test_set.mri[i]\n",
    "\n",
    "    pet_id = stripped_pet_file.split('/')[-1].replace('.pkl', '')\n",
    "    mri_id = stripped_mri_file.split('/')[-1].replace('.pkl', '')\n",
    "\n",
    "    with open(stripped_mri_file, 'rb') as fb:\n",
    "        stripped_mri = pickle.load(fb)\n",
    "\n",
    "    with open(stripped_pet_file, 'rb') as fb:\n",
    "        stripped_pet = pickle.load(fb)\n",
    "\n",
    "    nonstripped_pet_file = '/raidWorkspace/mingu/Data/ADNI/PUP_FBP/{}/pet_proc/w_{}_SUVR.nii.gz'.format(pet_id, pet_id)\n",
    "    nonstripped_pet = nib.load(nonstripped_pet_file).get_fdata()\n",
    "    nonstripped_pet = np.pad(nonstripped_pet, ((12, 12), (0, 0), (12, 12)), 'constant')\n",
    "\n",
    "    # get activation map\n",
    "    temp_set = np.array(Subset(test_set, [i]))\n",
    "    d = temp_set[0]\n",
    "    img, gcamp_map, guided_map, title = get_map(d, 'backbone.layer1', model, local_rank)\n",
    "\n",
    "    gcamp_map_t = np.abs(1 - gcamp_map)\n",
    "    tr = resize(gcamp_map_t, [145, 145, 145])\n",
    "    tr_m = tr.copy()\n",
    "    bmask = stripped_pet <= 0\n",
    "    tr_m[bmask] = np.nan\n",
    "\n",
    "    m = tr_m < hyparam.vmin\n",
    "    tr_m[m] = np.nan\n",
    "\n",
    "    guided_map_t = deepcopy(guided_map)\n",
    "    g_tr = resize(guided_map_t, [145, 145, 145])\n",
    "    g_tr_m = g_tr.copy()\n",
    "    bmask = stripped_pet <= 0\n",
    "    g_tr_m[bmask] = np.nan\n",
    "\n",
    "    m = g_tr_m < 0.2\n",
    "    g_tr_m[m] = np.nan\n",
    "\n",
    "    # show map\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    plt.suptitle(title + f' | {mri_id} | {pet_id}')\n",
    "\n",
    "    axs[0, 0].imshow(stripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 1].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "    axs[0, 2].imshow(nonstripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 2].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "    axs[0, 3].imshow(stripped_mri[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 3].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "    axs[1, 0].imshow(stripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 1].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "    axs[1, 2].imshow(nonstripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 2].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "    axs[1, 3].imshow(stripped_mri[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 3].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "    axs[2, 0].imshow(stripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 1].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    axs[2, 2].imshow(nonstripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 2].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    axs[2, 3].imshow(stripped_mri[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 3].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    \n",
    "    plt.savefig(f'../guided/{mri_id}_{pet_id}.png', dpi=400,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77f717-3335-4ee8-8557-9efec6b4dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
