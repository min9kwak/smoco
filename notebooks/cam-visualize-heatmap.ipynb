{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867b0ed-5e66-4b8a-9e38-1f68bd3f24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b963230-caf8-45bd-a724-6f7a2221076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc59ea-cd6c-4ffd-a130-a461b1907bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import rich\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from configs.finetune import FinetuneConfig\n",
    "from tasks.classification import Classification\n",
    "\n",
    "from models.backbone.base import calculate_out_features\n",
    "from models.backbone.densenet import DenseNetBackbone\n",
    "from models.backbone.resnet import build_resnet_backbone\n",
    "from models.head.projector import MLPHead\n",
    "from models.head.classifier import LinearClassifier\n",
    "\n",
    "from datasets.brain import BrainProcessor, Brain, BrainMoCo\n",
    "from datasets.transforms import make_transforms, compute_statistics\n",
    "\n",
    "from utils.logging import get_rich_logger\n",
    "from utils.gpu import set_gpu\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826b240-fe6f-4f19-b051-9a983495c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs =[(\"2022-07-02_08-00-31\", \"2022-07-03_13-41-32\"),\n",
    "        (\"2022-07-02_08-00-57\", \"2022-07-03_13-37-29\"),\n",
    "        (\"2022-07-02_09-38-52\", \"2022-07-03_13-33-23\"),\n",
    "        (\"2022-07-02_09-40-42\", \"2022-07-03_13-29-10\"),\n",
    "        (\"2022-07-02_11-17-38\", \"2022-07-03_13-25-05\"),\n",
    "        (\"2022-07-02_11-20-21\", \"2022-07-03_13-21-00\"),\n",
    "        (\"2022-07-02_17-15-14\", \"2022-07-03_13-16-54\"),\n",
    "        (\"2022-07-02_17-15-34\", \"2022-07-03_13-12-44\"),\n",
    "        (\"2022-07-02_18-53-46\", \"2022-07-03_13-08-35\"),\n",
    "        (\"2022-07-02_18-54-27\", \"2022-07-03_13-04-32\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff901a8-57f2-4e42-afc3-2583c4d94b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = ['3']\n",
    "server = 'dgx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b052387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "hash = hashs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e803ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f'./gcam/layer1/{hash[0]}-{hash[1]}/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff4669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b5b46-025c-4a96-86f4-8bbb209761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hash in hashs:\n",
    "    print(hash)\n",
    "    #######################\n",
    "    config = edict()\n",
    "    config.server = server\n",
    "    config.gpus = gpus\n",
    "    local_rank = 0\n",
    "\n",
    "    config.finetune_file = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/ckpt.last.pth.tar')\n",
    "    finetune_config = os.path.join(f'../checkpoints/pet-supmoco/resnet/{hash[0]}/finetune/{hash[1]}/configs.json')\n",
    "    with open(finetune_config, 'rb') as fb:\n",
    "        finetune_config = json.load(fb)\n",
    "\n",
    "    finetune_config_names = [\n",
    "        # data_parser\n",
    "        'data_type', 'root', 'data_info', 'mci_only', 'n_splits', 'n_cv',\n",
    "        'image_size', 'small_kernel', 'random_state',\n",
    "        'intensity', 'crop', 'crop_size', 'rotate', 'flip', 'affine', 'blur', 'blur_std', 'prob',\n",
    "        # model_parser\n",
    "        'backbone_type', 'init_features', 'growth_rate', 'block_config', 'bn_size', 'dropout_rate',\n",
    "        'arch', 'no_max_pool',\n",
    "        # train\n",
    "        'batch_size',\n",
    "        # moco / supmoco\n",
    "        'alphas',\n",
    "        # others\n",
    "        'task', 'projector_dim'\n",
    "    ]\n",
    "\n",
    "    for name in finetune_config_names:\n",
    "        if name in finetune_config.keys():\n",
    "            setattr(config, name, finetune_config[name])\n",
    "            \n",
    "    #########################################\n",
    "    set_gpu(config)\n",
    "    np.random.seed(config.random_state)\n",
    "    torch.manual_seed(config.random_state)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    # Networks\n",
    "    if config.backbone_type == 'densenet':\n",
    "        backbone = DenseNetBackbone(in_channels=1,\n",
    "                                    init_features=config.init_features,\n",
    "                                    growth_rate=config.growth_rate,\n",
    "                                    block_config=config.block_config,\n",
    "                                    bn_size=config.bn_size,\n",
    "                                    dropout_rate=config.dropout_rate,\n",
    "                                    semi=False)\n",
    "        activation = True\n",
    "    elif config.backbone_type == 'resnet':\n",
    "        backbone = build_resnet_backbone(arch=config.arch,\n",
    "                                         no_max_pool=config.no_max_pool,\n",
    "                                         in_channels=1,\n",
    "                                         semi=False)\n",
    "        activation = False\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if config.small_kernel:\n",
    "        backbone._fix_first_conv()\n",
    "\n",
    "    if config.crop:\n",
    "        out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.crop_size)\n",
    "    else:\n",
    "        out_dim = calculate_out_features(backbone=backbone, in_channels=1, image_size=config.image_size)\n",
    "    classifier = LinearClassifier(in_channels=out_dim, num_classes=2, activation=activation)\n",
    "\n",
    "    backbone.load_weights_from_checkpoint(path=config.finetune_file, key='backbone')\n",
    "    classifier.load_weights_from_checkpoint(path=config.finetune_file, key='classifier')\n",
    "\n",
    "    # load finetune data\n",
    "    data_processor = BrainProcessor(root=config.root,\n",
    "                                    data_info=config.data_info,\n",
    "                                    data_type=config.data_type,\n",
    "                                    mci_only=config.mci_only,\n",
    "                                    random_state=config.random_state)\n",
    "    datasets = data_processor.process(n_splits=config.n_splits, n_cv=config.n_cv)\n",
    "\n",
    "    # intensity normalization\n",
    "    assert config.intensity in [None, 'scale', 'minmax']\n",
    "    mean_std, min_max = (None, None), (None, None)\n",
    "    if config.intensity is None:\n",
    "        pass\n",
    "    elif config.intensity == 'scale':\n",
    "        pass\n",
    "    elif config.intensity == 'minmax':\n",
    "        with open(os.path.join(config.root, 'labels/minmax.pkl'), 'rb') as fb:\n",
    "            minmax_stats = pickle.load(fb)\n",
    "            min_max = (minmax_stats[config.data_type]['min'], minmax_stats[config.data_type]['max'])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    train_transform, test_transform = make_transforms(image_size=config.image_size,\n",
    "                                                      intensity=config.intensity,\n",
    "                                                      min_max=min_max,\n",
    "                                                      crop_size=config.crop_size,\n",
    "                                                      rotate=config.rotate,\n",
    "                                                      flip=config.flip,\n",
    "                                                      affine=config.affine,\n",
    "                                                      blur_std=config.blur_std,\n",
    "                                                      prob=config.prob)\n",
    "    \n",
    "    #########################################\n",
    "    train_set = Brain(dataset=datasets['train'], data_type=config.data_type, transform=test_transform)\n",
    "    test_set = Brain(dataset=datasets['test'], data_type=config.data_type, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=1, drop_last=False)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=1, drop_last=False)\n",
    "    \n",
    "    #######################################\n",
    "    for layer in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "        model = ModelViz(backbone=backbone, classifier=classifier, local_rank=local_rank)\n",
    "        gcam = GradCAMpp(model, f'backbone.{layer}')\n",
    "        #########################################\n",
    "        norm_cnt, ab_cnt = 0, 0\n",
    "        avg_map_norm = np.zeros((64, 64, 64))\n",
    "        avg_map_ab = np.zeros((64, 64, 64))\n",
    "\n",
    "        for mode, loader in zip(['train', 'test'], [train_loader, test_loader]):\n",
    "\n",
    "            for batch in tqdm.tqdm(loader):\n",
    "                x = batch['x'].to(local_rank)\n",
    "\n",
    "                logit = model(x)\n",
    "                if batch['y'].item() == logit.argmax().item():\n",
    "                    gcam_map = gcam(x)\n",
    "                    gcam_map = gcam_map.cpu().numpy()[0][0]\n",
    "                    gcam_map = np.abs(1 - gcam_map)        \n",
    "                    if not np.isnan(gcam_map).any():    \n",
    "                        if batch['y'].item() == 0:\n",
    "                            avg_map_norm = avg_map_norm * norm_cnt + gcam_map\n",
    "                            norm_cnt = norm_cnt + 1\n",
    "                            avg_map_norm = avg_map_norm / norm_cnt\n",
    "                        else:\n",
    "                            avg_map_ab = avg_map_ab * ab_cnt + gcam_map\n",
    "                            ab_cnt = ab_cnt + 1\n",
    "                            avg_map_ab = avg_map_ab / ab_cnt\n",
    "\n",
    "            #################################\n",
    "            os.makedirs(f'gcam/{layer}/{hash[0]}-{hash[1]}', exist_ok=True)\n",
    "            with open(f'gcam/{layer}/{hash[0]}-{hash[1]}/{mode}-normal.pkl', 'wb') as fb:\n",
    "                pickle.dump(avg_map_norm, fb)\n",
    "            with open(f'gcam/{layer}/{hash[0]}-{hash[1]}/{mode}-abnormal.pkl', 'wb') as fb:\n",
    "                pickle.dump(avg_map_ab, fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8eb078-7b02-42be-be53-0b80272a2dc7",
   "metadata": {},
   "source": [
    "## Filter only correct samples and save visualization maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07693dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0, 0, :, :, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0deb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axs[0].imshow(x[32, :, :], cmap='binary')\n",
    "axs[1].imshow(x[32, :, :], cmap='binary')\n",
    "axs[1].imshow(avg_map_ab[32, :, :], cmap='jet', alpha=0.2,)\n",
    "axs[2].imshow(x[:, 32, :], cmap='binary')\n",
    "axs[2].imshow(avg_map_ab[:, 32, :], cmap='jet', alpha=0.2,)\n",
    "axs[3].imshow(x[:, :, 32], cmap='binary')\n",
    "axs[3].imshow(avg_map_ab[:, :, 32], cmap='jet', alpha=0.2,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db04e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e7c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bd80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf39dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c160674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gcam_2 = GradCAMpp(model, ['layer2'])\n",
    "gcam_3 = GradCAMpp(model, ['layer3'])\n",
    "gcam_4 = GradCAMpp(model, ['layer4'])\n",
    "guided = GuidedBackpropGrad(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad99b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53e82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333f24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.backbone.eval()\n",
    "    model.classifier.eval()\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        logit = model(batch['x'].float().to(local_rank))\n",
    "        if (batch['y'] == logit.argmax().cpu()).item():\n",
    "            \n",
    "        else:\n",
    "            pass            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d71da-e436-4d3f-918d-49f1fbbcdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(data, target_layer, model, local_rank):\n",
    "    \n",
    "    model.backbone.eval()\n",
    "    model.classifier.eval()\n",
    "    \n",
    "    gcam = GradCAMpp(model, target_layer)\n",
    "    guided = GuidedBackpropGrad(model)\n",
    "    \n",
    "    # predict\n",
    "    x = torch.as_tensor(data['x'][None].to(local_rank))        \n",
    "    pred_logits = model(x)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    pred_label = pred_logits.argmax(dim=1).item()\n",
    "    pred_prob = torch.nn.functional.softmax(pred_logits, dim=1)[0, pred_label].item() * 100\n",
    "\n",
    "    title = f\"Pred: {pred_label} ({pred_prob:.2f}%) | True: {data['y']}\"\n",
    "\n",
    "    # image\n",
    "    img = torch.moveaxis(x, 1, -1)\n",
    "\n",
    "    # gradcam\n",
    "    gcam_map = gcam(x=x, class_idx=pred_label)[0]\n",
    "    model.zero_grad()\n",
    "\n",
    "    # guided\n",
    "    guided_map = guided(x)\n",
    "    model.zero_grad()\n",
    "    guided_map = torch.sum(guided_map ** 2, dim=1) ** 0.5\n",
    "    \n",
    "    # shape\n",
    "    img = img.cpu().detach().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    \n",
    "    gcam_map = gcam_map.cpu().detach().numpy()\n",
    "    gcam_map = np.squeeze(gcam_map)\n",
    "    \n",
    "    guided_map = guided_map.cpu().detach().numpy()\n",
    "    guided_map = np.squeeze(guided_map)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    return img, gcam_map, guided_map, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb0da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4028af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e410ef-9f3d-49f9-a29d-bf1ae2e8f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    print(layer)\n",
    "    os.makedirs(f'../cam/{layer}', exist_ok=True)\n",
    "    for i in pmci_idx:\n",
    "\n",
    "        # load data\n",
    "        stripped_pet_file = test_set.pet[i]\n",
    "        stripped_mri_file = test_set.mri[i]\n",
    "\n",
    "        pet_id = stripped_pet_file.split('/')[-1].replace('.pkl', '')\n",
    "        mri_id = stripped_mri_file.split('/')[-1].replace('.pkl', '')\n",
    "\n",
    "        with open(stripped_mri_file, 'rb') as fb:\n",
    "            stripped_mri = pickle.load(fb)\n",
    "\n",
    "        with open(stripped_pet_file, 'rb') as fb:\n",
    "            stripped_pet = pickle.load(fb)\n",
    "\n",
    "        nonstripped_pet_file = '/raidWorkspace/mingu/Data/ADNI/PUP_FBP/{}/pet_proc/w_{}_SUVR.nii.gz'.format(pet_id, pet_id)\n",
    "        nonstripped_pet = nib.load(nonstripped_pet_file).get_fdata()\n",
    "        nonstripped_pet = np.pad(nonstripped_pet, ((12, 12), (0, 0), (12, 12)), 'constant')\n",
    "\n",
    "        # get activation map\n",
    "        temp_set = np.array(Subset(test_set, [i]))\n",
    "        d = temp_set[0]\n",
    "        img, gcamp_map, guided_map, title = get_map(d, f'backbone.{layer}', model, local_rank)\n",
    "\n",
    "        gcamp_map_t = np.abs(1 - gcamp_map)\n",
    "        tr = resize(gcamp_map_t, [145, 145, 145])\n",
    "        tr_m = tr.copy()\n",
    "        bmask = stripped_pet <= 0\n",
    "        tr_m[bmask] = np.nan\n",
    "\n",
    "        m = tr_m < hyparam.vmin\n",
    "        tr_m[m] = np.nan\n",
    "\n",
    "        # show map\n",
    "        fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "        plt.suptitle(title + f' | {mri_id} | {pet_id}')\n",
    "\n",
    "        axs[0, 0].imshow(stripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 1].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "        axs[0, 2].imshow(nonstripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 2].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "        axs[0, 3].imshow(stripped_mri[hyparam.loc1, :, :], cmap='binary')\n",
    "        axs[0, 3].imshow(tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        axs[1, 0].imshow(stripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 1].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "        axs[1, 2].imshow(nonstripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 2].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "        axs[1, 3].imshow(stripped_mri[:, hyparam.loc2, :], cmap='binary')\n",
    "        axs[1, 3].imshow(tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        axs[2, 0].imshow(stripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 1].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "        axs[2, 2].imshow(nonstripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 2].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "        axs[2, 3].imshow(stripped_mri[:, :, hyparam.loc3], cmap='binary')\n",
    "        axs[2, 3].imshow(tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "\n",
    "        plt.savefig(f'../cam/{layer}/{mri_id}_{pet_id}.png', dpi=400,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806ebce-3651-49de-901e-b1040cbe81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(f'../guided/', exist_ok=True)\n",
    "for i in pmci_idx:\n",
    "\n",
    "    # load data\n",
    "    stripped_pet_file = test_set.pet[i]\n",
    "    stripped_mri_file = test_set.mri[i]\n",
    "\n",
    "    pet_id = stripped_pet_file.split('/')[-1].replace('.pkl', '')\n",
    "    mri_id = stripped_mri_file.split('/')[-1].replace('.pkl', '')\n",
    "\n",
    "    with open(stripped_mri_file, 'rb') as fb:\n",
    "        stripped_mri = pickle.load(fb)\n",
    "\n",
    "    with open(stripped_pet_file, 'rb') as fb:\n",
    "        stripped_pet = pickle.load(fb)\n",
    "\n",
    "    nonstripped_pet_file = '/raidWorkspace/mingu/Data/ADNI/PUP_FBP/{}/pet_proc/w_{}_SUVR.nii.gz'.format(pet_id, pet_id)\n",
    "    nonstripped_pet = nib.load(nonstripped_pet_file).get_fdata()\n",
    "    nonstripped_pet = np.pad(nonstripped_pet, ((12, 12), (0, 0), (12, 12)), 'constant')\n",
    "\n",
    "    # get activation map\n",
    "    temp_set = np.array(Subset(test_set, [i]))\n",
    "    d = temp_set[0]\n",
    "    img, gcamp_map, guided_map, title = get_map(d, 'backbone.layer1', model, local_rank)\n",
    "\n",
    "    gcamp_map_t = np.abs(1 - gcamp_map)\n",
    "    tr = resize(gcamp_map_t, [145, 145, 145])\n",
    "    tr_m = tr.copy()\n",
    "    bmask = stripped_pet <= 0\n",
    "    tr_m[bmask] = np.nan\n",
    "\n",
    "    m = tr_m < hyparam.vmin\n",
    "    tr_m[m] = np.nan\n",
    "\n",
    "    guided_map_t = deepcopy(guided_map)\n",
    "    g_tr = resize(guided_map_t, [145, 145, 145])\n",
    "    g_tr_m = g_tr.copy()\n",
    "    bmask = stripped_pet <= 0\n",
    "    g_tr_m[bmask] = np.nan\n",
    "\n",
    "    m = g_tr_m < 0.2\n",
    "    g_tr_m[m] = np.nan\n",
    "\n",
    "    # show map\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    plt.suptitle(title + f' | {mri_id} | {pet_id}')\n",
    "\n",
    "    axs[0, 0].imshow(stripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 1].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "    axs[0, 2].imshow(nonstripped_pet[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 2].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "    axs[0, 3].imshow(stripped_mri[hyparam.loc1, :, :], cmap='binary')\n",
    "    axs[0, 3].imshow(g_tr_m[hyparam.loc1, :, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "    axs[1, 0].imshow(stripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 1].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "    axs[1, 2].imshow(nonstripped_pet[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 2].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "    axs[1, 3].imshow(stripped_mri[:, hyparam.loc2, :], cmap='binary')\n",
    "    axs[1, 3].imshow(g_tr_m[:, hyparam.loc2, :], cmap='jet', alpha=0.2,)\n",
    "\n",
    "    axs[2, 0].imshow(stripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 1].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    axs[2, 2].imshow(nonstripped_pet[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 2].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    axs[2, 3].imshow(stripped_mri[:, :, hyparam.loc3], cmap='binary')\n",
    "    axs[2, 3].imshow(g_tr_m[:, :, hyparam.loc3], cmap='jet', alpha=0.2,)\n",
    "    \n",
    "    plt.savefig(f'../guided/{mri_id}_{pet_id}.png', dpi=400,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77f717-3335-4ee8-8557-9efec6b4dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
